{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6331d6d1-5ce6-4bd7-ba3d-7a2b382b0bf2",
   "metadata": {},
   "source": [
    "# Notebook for Topic 5 - Time Series anomaly detection\n",
    "\n",
    "<hr style=\"border-top: 1px solid #001a79;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c71ff-47a9-4917-98d6-827024be9903",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e8fa9-9620-49eb-a840-0f0bc5ec9c2d",
   "metadata": {},
   "source": [
    "This Notebook is a recreation of instructions from the blogpost 'Timeseries anomaly detection using an Autoencoder' available https://keras.io/examples/timeseries/timeseries_anomaly_detection/\n",
    "\n",
    "In this notebook, I will demonstrate the use of Keras and TensorFlow to build and train a model for timeseries anomaly detection using the NAB (Numenta Anomaly Benchmark) dataset. The NAB dataset is a collection of labeled timeseries data files that are commonly used to evaluate the performance of anomaly detection algorithms. I will use Keras and TensorFlow to build and train a deep learning model that can detect anomalies in the NAB timeseries data. I will start by setting up the environment and loading the necessary libraries, then I will explore the NAB dataset and preprocess the data for use with the model. Next, I will build and train the model, and finally I will evaluate its performance on the NAB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c5894-e9b8-45cd-a6b5-c79bd31d3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# library for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# package for building and training deep learning models in TensorFlow.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# library for data visualization\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141e35e-d984-4a26-9222-d8efec099d4b",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "In this example, data from the NAB Data Corpus will be used: https://github.com/numenta/NAB/tree/master/data\n",
    "\n",
    "The NAB corpus is a collection of 58 timeseries data files that are intended for use in research on streaming anomaly detection. The data includes both real-world and artificial timeseries data, and contains labeled anomalous periods of behavior. The data is composed of ordered, timestamped, single-valued metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b88c6-89b3-4386-94f8-1e734d437133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the Github NAB data repository\n",
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "# Parse a URL for dataset without anomaly\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "\n",
    "# Parse a URL for dataset with anomaly\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "\n",
    "\n",
    "\n",
    "# Download dataset without anomaly\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# Download dataset with anomaly\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd0bb3-9c9e-4227-a8ba-0c348d91ad4e",
   "metadata": {},
   "source": [
    "#### Print the 5 first rows of data\n",
    "\n",
    "Display the first few rows of downloaded data for previewing, checking the integrity of, and debugging the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ea1a2-ce1c-4b4d-99ae-40495deff3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows of data without Anomalies:\")\n",
    "df_small_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fb6be-d06d-4ec4-ba2d-779756c89810",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows of data with Anomalies:\")\n",
    "df_daily_jumpsup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce237a-4e30-460a-91b0-57d0efdc9c6a",
   "metadata": {},
   "source": [
    "## Visualise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b1c336-9d2b-445b-a6e3-6406550b7950",
   "metadata": {},
   "source": [
    "#### Data without anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b56824-09c3-48c9-b1a9-5b49ed126633",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0c3fd-9827-40b6-83f9-c76623acf2e6",
   "metadata": {},
   "source": [
    "#### Data with anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a887b9a-ee79-4e22-989e-4cdac0309cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2731bd-78c6-43be-ad45-93225c484478",
   "metadata": {},
   "source": [
    "## Prepare the training data\n",
    "\n",
    "For training purposes, the dataset without anomalies will bu used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1d1cf-8e0a-4b7f-9288-b4ce464576f4",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f4f88-96f5-485a-a5aa-7854ccc13c0b",
   "metadata": {},
   "source": [
    "Normalization is a common preprocessing step in machine learning that involves transforming the data so that it has zero mean and unit variance. This can be useful for algorithms that are sensitive to the scale of the input data, as it helps to ensure that all features are on a similar scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c0c47-78a2-4963-b118-db0cabc4c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and save the values of the mean and standard deviation of the no anomalies dataset\n",
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "\n",
    "# Displaye the values\n",
    "print('Mean value of no anomalies dataset: {:.3f}'.format(training_mean.value))\n",
    "print('Standard Deviation of no anomalies dataset: {:.3f}'.format(training_std.value))\n",
    "\n",
    "# Normalize the no anomalies dataset\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"\\nNumber of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6889ea5-fb35-4e8a-8cbf-dc9574426904",
   "metadata": {},
   "source": [
    "#### Visualise the normalized no anomalies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164e60d-22e2-49a7-8b9c-5a4de5125ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "df_training_value.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1abd3c-9569-44dd-bdc8-206285c3f0af",
   "metadata": {},
   "source": [
    "#### Create sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f36067-9240-47a5-b558-b59fb05cdf38",
   "metadata": {},
   "source": [
    "The function below will be used to create a set of input sequences for training a ML model. This function will create overlapping sequences of the input values, with each sequence shifted by 1 value comparing to the previous one. This allows the model to learn dependencies between the values at different time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744feba2-214c-4048-a186-956e3d08af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Input Array:\")\n",
    "        print(values)\n",
    "        print(\"\\nSliding Windows:\")        \n",
    "        \n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        app_values = values[i : (i + time_steps)]\n",
    "        if verbose:\n",
    "            print(\"Window nr {}: {}\".format(i+1, app_values))\n",
    "        output.append(app_values)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"\\nFinal Array:\")\n",
    "        pprint(output)\n",
    "        \n",
    "    return np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae37f4a-ae35-45ae-9ac2-66da73f1ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of 'create_sequences' usage:\n",
    "seq_example = create_sequences([1,2,3,4,5,6,7,8,9,10], time_steps=4, verbose=True);\n",
    "seq_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9881c09-589d-4c1a-b834-4dfd10b9581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The alternative below should be more efficient than the original implementation of 'create_sequences',\n",
    "# as it avoids the overhead of creating and appending to a Python list and use more efficient NumPy array slicing instead.\n",
    "\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    values = np.asarray(values)\n",
    "    return np.stack([values[i : (i + time_steps)] for i in range(len(values) - time_steps + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421856e-3bc9-410f-944f-9ed4e4b019fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use normalised no anomalies dataset\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bce6f5-3981-4ffe-933b-ec41eb102c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the training input data x_train \n",
    "\n",
    "print(\"\\nShape of the the training input data x_train:\\n\")\n",
    "print(\" Number of sequences: {}\\n Sequence length: {} \\n Sequence Height: {}\".format(x_train.shape[0], x_train.shape[1], x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0987b98-4553-4a32-b234-3de739a35d3c",
   "metadata": {},
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1450c70-3bd4-4103-ae9b-13a0d327a06e",
   "metadata": {},
   "source": [
    "#### What is Convolution?\n",
    "\n",
    "Convolution is a mathematical operation that is commonly used in signal and image processing to modify or extract information from a signal or image. It involves sliding a kernel (also called a filter or mask) over the input matrix and applying element-wise multiplication and summing the results to produce a single output value at each position.\n",
    "\n",
    "Below is the example of convolution of the 1D input array A = [1,2,3,4,5] and the kernel = [1,2,3]. Note below, that in the convolution operation, the second array (kernel) is flipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0c8d2-5192-4c48-91e5-7da483facc9a",
   "metadata": {},
   "source": [
    "$C_1 = 1*1 = 1$\n",
    "\n",
    "|              |    |    |    |    |    |    |    |    |    |     $C_1$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|----|--------------|\n",
    "| Input Array  |    |    | <td style=\"border: 1px solid red;\">**1** </td> |  2  | 3  | 4  | 5  |   |    |  **1**      |\n",
    "| Kernel       | 3  | 2  | <td style=\"border: 1px solid red;\">**1** </td>      |    |    |    |      |    |           |\n",
    "\n",
    "\n",
    "$C_2 = 1*2+2*1 = 4$\n",
    "\n",
    "|              |    |    |    |    |    |    |    |    |    |     $C_2$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|----|--------------|\n",
    "| Input Array  |    |    |<td style=\"border: 1px solid red;\">**1** </td>   <td style=\"border: 1px solid red;\">**2** </td> |  3  | 4  | 5  |    |    |   **4**      |\n",
    "| Kernel       |    | 3  |<td style=\"border: 1px solid red;\">**2** </td>   <td style=\"border: 1px solid red;\">**1** </td>       |    |    |       |    |              |\n",
    "\n",
    "$C_3 = 1*3+2*2+3*1 = 10$\n",
    "\n",
    "|              |    |    |    |    |    |    |    |    |    |     $C_3$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|----|--------------|\n",
    "| Input Array  |    |    |<td style=\"border: 1px solid red;\">**1** </td>   <td style=\"border: 1px solid red;\">**2** </td><td style=\"border: 1px solid red;\">**3** </td> | 4 |5 | | |**10** |\n",
    "| Kernel       |    |    | <td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**2** </td>   <td style=\"border: 1px solid red;\">**1** </td>  | | | | |\n",
    "\n",
    "\n",
    "$C_4 = 2*3 + 3*2 + 4*1 = 16$\n",
    "\n",
    "|            |    |    |    |    |    |    |    |    |      |  $C_4$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|------|----------|\n",
    "| Input Array  |    |    | 1  <td style=\"border: 1px solid red;\">**2** </td><td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**4** </td> |5 | | | |**16** |\n",
    "| Kernel       |    |    | <td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**2** </td>   <td style=\"border: 1px solid red;\">**1** </td>   |  | | |\n",
    "\n",
    "\n",
    "$C_5 = 3*3+4*2+5*1 = 22$\n",
    "\n",
    "|             |    |    |    |    |    |    |    |    |      |  $C_5$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|------|----------|\n",
    "| Input Array  |    |    | 1 | 2 <td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**4** </td> <td style=\"border: 1px solid red;\">**5** </td>| | | |**22** |\n",
    "| Kernel       |    |    |    |<td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**2** </td>   <td style=\"border: 1px solid red;\">**1** </td>    | | |\n",
    "\n",
    "\n",
    "$C_6 = 4*3+5*2 = 22$\n",
    "\n",
    "|            |    |    |    |    |    |    |    |    |      |  $C_6$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|------|----------|\n",
    "| Input Array  |    |    | 1 | 2 | 3  <td style=\"border: 1px solid red;\">**4** </td> <td style=\"border: 1px solid red;\">**5** </td>| | | |**22** |\n",
    "| Kernel       |    |    |    |  |<td style=\"border: 1px solid red;\">**3** </td>  <td style=\"border: 1px solid red;\">**2** </td> | 1     | | |\n",
    "\n",
    "\n",
    "$C_7 = 5*3 = 15$\n",
    "\n",
    "|             |    |    |    |    |    |    |    |    |      |  $C_7$   |\n",
    "|--------------|----|----|----|----|----|----|----|----|------|----------|\n",
    "| Input Array  |    |    | 1 | 2 | 3 | 4 </td> <td style=\"border: 1px solid red;\">**5** </td>| | | |**15** |\n",
    "| Kernel       |    |    |    |  |   |<td style=\"border: 1px solid red;\">**3** </td>  | 2 | 1     | |\n",
    "\n",
    "\n",
    "Result of the Convoultion of the input array A = [1,2,3,4,5] and the kernel = [1,2,3] is: \n",
    "\n",
    "$C = (A * kernel) = [1,4,10,16,22,22,15] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff63a77-7b80-42d0-80a0-16f9ae949598",
   "metadata": {},
   "source": [
    "#### What is a Transposed Convolution?\n",
    "\n",
    "In a transposed convolution, the kernel is used to upsample the input data by inserting zeros between the original data points, and then applying a standard convolution operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897173c8-7a9b-436d-acd6-f005577991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm the above manual calculations using Numpy convolve function:\n",
    "\n",
    "# Define the input array and kernel\n",
    "A = np.array([1, 2, 3, 4, 5])\n",
    "kernel = np.array([1, 2, 3])\n",
    "\n",
    "# Perform the convolution using NumPy's convolve() function\n",
    "output_array = np.convolve(A, kernel, 'full')\n",
    "\n",
    "print(output_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae26ed-d36a-45c9-97d5-8d6f8b602962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Sequential Model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to th Sequential model\n",
    "\n",
    "# First, define the shape of the input data using the sample length and height\n",
    "model.add(layers.Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# Add layer to perform 1D convolution of the input data\n",
    "# filters - number of outputs in the convolution\n",
    "# kernel_size - size of the kernel for convolution operation. By default, kernel is initialized by drawing random samples from a uniform distribution\n",
    "# strides - the distance between the starting points of two consecutive convolutions. The amount by which kernel is shifted when sliding across the input array\n",
    "# padding = \"same\" - padding with zeros evenly to the left/right of the input such that output has the same width dimension as the input\n",
    "# Output: 3D matrix with the following shape: 'Number of sequences' x 'Input Array length/strides' x 'filters'\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"))\n",
    "\n",
    "# Randomly set 20% of the outputs from the previous layer to 0.\n",
    "# This is used to help reduce the risk of overfitting to the training data.\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "# Add layer to perform 1D convolution of the input data. Layer similar to the one above, but it has only 16 outputs\n",
    "model.add(layers.Conv1D(filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"))\n",
    "\n",
    "# Add transposed convolutional layer\n",
    "# filters - number of outputs in the convolution\n",
    "# kernel_size - size of the kernel for convolution operation. By default, kernel is initialized by drawing random samples from a uniform distribution\n",
    "# padding = \"same\" - padding with zeros evenly to the left/right of the input such that output has the same width dimension as the input\n",
    "# strides - the distance between the starting points of two consecutive convolutions. The amount by which kernel is shifted when sliding across the input array\n",
    "# Output: 3D matrix with the following shape: 'Number of sequences' x 'Input Array length * 2' x 'filters'\n",
    "model.add(layers.Conv1DTranspose(filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"))\n",
    "\n",
    "# Randomly set 20% of the outputs from the previous layer to 0.\n",
    "# This is used to help reduce the risk of overfitting to the training data.\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "model.add(layers.Conv1DTranspose(filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87f937-7ce9-4f3c-a9ba-afc195fd12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and siplay the summary\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e00c82-7e84-4a72-bd44-94df46b9749f",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac702d4-5f48-41d2-89b5-9efc72abe58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c3c08-b16c-4b6b-97ad-6b7f85e20086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e985e5a-d061-40ae-afb3-47dbccd56f53",
   "metadata": {},
   "source": [
    "## Detecting anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f01421-f469-4160-96b5-dacc04cb5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a306fa-51fb-4ef5-833b-60d104dcf64a",
   "metadata": {},
   "source": [
    "#### Compare recontruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb0291-ad81-44de-a762-dafeb344c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[0])\n",
    "plt.plot(x_train_pred[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c759d5-6b9f-4fa8-b578-e6e16adf2c7d",
   "metadata": {},
   "source": [
    "#### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d42367-d077-4ca1-88dc-dfed894c5b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
    "fig, ax = plt.subplots()\n",
    "df_test_value.plot(legend=False, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Create sequences from test values.\n",
    "x_test = create_sequences(df_test_value.values)\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "test_mae_loss = test_mae_loss.reshape((-1))\n",
    "\n",
    "plt.hist(test_mae_loss, bins=50)\n",
    "plt.xlabel(\"test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Detect all the samples which are anomalies.\n",
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8230263-a808-45f8-bf15-c3a06cce8fe1",
   "metadata": {},
   "source": [
    "## Plot anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfb42a-160c-4d75-8515-4ba47d8a05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
    "        anomalous_data_indices.append(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f44dfb-4d5e-4e3c-a55d-86459f563c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad41920-b661-4a6b-86f7-6ef576ba91c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
